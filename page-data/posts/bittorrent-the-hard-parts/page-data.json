{"componentChunkName":"component---src-templates-post-js","path":"/posts/bittorrent-the-hard-parts","result":{"data":{"markdownRemark":{"id":"8ff471b4-35a1-5d8e-9ea6-d5ce0b61664e","html":"<h2>About these posts</h2>\n<p>I've been working on a <a href=\"https://github.com/cronokirby/haze\">bittorrent client</a> in haskell\nrecently. It's now at the point where it can download torrents in the wild.</p>\n<p>The <a href=\"https://wiki.theory.org/index.php/BitTorrentSpecification\">protocol itself</a>\nis well specified, although it takes a few read-throughs to get the hang of it.\nThe first time I read through the protocol I didn't understand much. But as I started\nimplementing different parts of the protocol, those parts of the document started making\nmore and more sense.</p>\n<p>That being said, there are still many parts of the protocol where the specification might\nbe clear, but <em>how</em> to implement that specification is left as an exercise to the reader.\nOne of the sections that's most guilty of this is the section related to how peer's operate.\nThere are many subtle rules about what peers should do in certain situations; the details\nof what variables to keep track of and how to make sure all these conditions are satisfied\nis a big leap from this description though.</p>\n<p>In these series of posts, I want to try and explain the details that go into some of the algorithms\nnecessary to implement <strong>Bittorrent</strong>.</p>\n<p>This post covers how to save the pieces that make up the data in a torrent to disk, and how to recompose\nthose pieces back together.</p>\n<h3>Side Note: What is Bittorrent?</h3>\n<p>If you're already familiar with <strong>torrents</strong> or <strong>Bittorrent</strong>, then this section can be safely ignored.</p>\n<p>Let me briefly explain these concepts.</p>\n<p>Fundamentally, <strong>Bittorrent</strong> is a protocol that defines a way for multiple computers, which\nwe refer to as \"peers\", to download a file from eachother. Instead of each peer downloading\nthe file from a central server, they instead download different parts from eachother, and upload\nthe parts they have to the other peers that want those parts.</p>\n<p>A <strong>torrent</strong> refers to this group of peers sharing a file.</p>\n<h2>Torrents and Pieces</h2>\n<p>A torrent can contain either a single file, or multiple files. When a torrent contains multiple files,\nit can optionally contain a root directory for those files. For example, <code>blockbuster.torrent</code> might\ncontain a single <code>blockbuster.mp4</code> file, or perhaps <code>blockbuster.mp4, blockbuster.subtitles</code> in a <code>blockbuster</code> folder.</p>\n<p>I mentioned previously that peers trade \"parts\" of a file. Instead of considering each peer as either having\nthe entire file, or not having it, and then downloading from those that have the <strong>whole</strong> file, we divide the file\ninto parts. We call these parts <strong>pieces</strong>. At any given point in time, we know which peers have which pieces (or at least, claim to), and what\npieces we have, and can make decisions about which piece to download next from whom.</p>\n<p>The piece is also the unit of integrity of the torrent. Each piece has a SHA1 hash associated with it,\nand when we receive a piece, we can hash the data inside, and see if it matches. This allows us to make sure that we're not\ndownloading junk data.</p>\n<h2>Pieces and Division</h2>\n<p>A torrent contains information about what files are in it, as mentioned previously. It also contains information about\nhow big the pieces are: this is a single number specifying how big each piece is.</p>\n<p><strong>Complication: All pieces are the same size, except for the last one.</strong>\nLet me illustrate this problem with an example. Let's say our piece size is 2 bytes, and our torrent contains 5 bytes\nin total (let's skim over how this data is divided into files for now). Our data is divided like this:</p>\n<pre><code class=\"language-txt\">xx xx x\n</code></pre>\n<p>The first 2 pieces have the announced size, 2 bytes, but the last piece has to be whatever size necessary to \"plug in\"\nthe end of the data.</p>\n<p>This is just an edge case to worry about, and not as tricky as the next complication:</p>\n<p><strong>Complication: Pieces don't belong to one file</strong>\nLet's continue using the same example as the previous complication, but further specify that the torrent actually\ncontains 2 files: A.png B.png. A is 3 bytes, and B 2 bytes. Our data would now look like this:</p>\n<pre><code class=\"language-txt\">AA AB B\n</code></pre>\n<p>The second piece now contains data from 2 different files!</p>\n<p>This is because, as far as pieces are concerned, the torrent is just a binary blob. When peers are trading\npieces it's as if the torrent just contained a single file. In fact, in the case of a single file, we don't have this\nproblem at all, since all the pieces belong to this file.</p>\n<p>When there are multiple files, they have a defined order. Conceptually, the binary data in these files\nis concatenated together, in this predefined order, and then piece division happens as if it were a single file.\nThis means that a piece may actually contain data belonging to an arbitrary of files. It's actually quite\ncommon for a piece to overlap many files. Because movies, which are large, often come with subtitles, which are relatively\nmuch smaller, the piece size we use for those torrents are usually larger than the size of all the subtitles combined.\nIt's not uncommon for a single piece to actually contain all of the subtitles as well as a chunk of the movie itself:</p>\n<pre><code class=\"language-txt\">ABCDEFGHIJXXXXXXXX XXXXX...\n</code></pre>\n<h2>What our algorithm needs to do</h2>\n<p>Now we get to the crux of this post: the algorithm for saving and retrieving pieces.</p>\n<p>We can break down what we do with pieces into 3 seperate tasks:</p>\n<ul>\n<li>Recomposing the pieces into the torrent's files</li>\n<li>Saving pieces to disk</li>\n<li>Reading pieces from disk</li>\n</ul>\n<h3>Recomposing the pieces into the torrent's files</h3>\n<p>After we've downloaded all the pieces, we need to actually assemble the files\nthat compose the torrent from the binary data in those pieces. We need to handle this somehow.\nOne option would be to wait until we have all pieces and then glue them together, another would be\nto save to files as soon as we have all the pieces in that file.</p>\n<h3>Saving the pieces to disk</h3>\n<p>Although we could keep all pieces in memory until we have them all, and then flush them out to disk,\nthis doesn't work very well for actual torrents, which can easily be multiple gigabytes in size.\nWe need a way to save pieces to disk as they arrive, in such a way that we can easily recompose the pieces\ninto the files that make up the torrent once we have them all.</p>\n<h3>Reading pieces from disk</h3>\n<p>A key aspect of bittorrent is that peers aren't just downloading from other peers, but also\nuploading the pieces of the files that they already have. Since we don't keep pieces in memory,\nbut instead save them to disk, we need a way to retrieve these pieces from disk. We also need\nto be able to do this no matter what stage we're at. We need a way to read pieces back, whether\nwe've glued the pieces back into the torrent files yet or not.</p>\n<p>I've stuck to details of the protocol itself so far. Now I'm going to describe the approach I came\nup with for this algorithm. This is not at all a unique approach, nor is it the only, or best way\nto tackle this problem.</p>\n<h2>Piece files, start files, and end files</h2>\n<p>Before we can even start on an algorithm to save pieces to to the right place, we need to decide\non what the \"right place\" is in the first place.</p>\n<p>One choice would be to always work within\nthe files in the torrent: when we save a piece, we save different bits of the piece to different sections\nof different files. We modify the final files directly. This has the advantage of not needing a final\nrecomposition step, since we're always working with the files themselves. The disadvantage is that the operation\nof figuring out which sections of which files to write to is quite complicated.</p>\n<p>Another approach, which is the one I chose, is instead to use as many files as convenient, and then\nrecompose them together as a final step. For example, instead of trying to figure out where \"piece #38\"\nneeds to go, we just save it in <code>piece-38.bin</code> and worry about recomposing it later.</p>\n<p>We identify the following cases for how we save pieces:</p>\n<ul>\n<li>The piece belongs completely into a single file:</li>\n</ul>\n<pre><code class=\"language-txt\">..xx xxxx xx..\n</code></pre>\n<p>In this case we save <code>piece #N</code> to <code>piece-N.bin</code>.</p>\n<ul>\n<li>The piece belongs to multiple files:</li>\n</ul>\n<p>In this case, we will save the piece into N files, where N is the number of\nfiles the piece belongs to. What these files are named depends on the following:</p>\n<ul>\n<li>If a file fits completely into a piece:</li>\n</ul>\n<pre><code class=\"language-txt\">xxAAAyy\n</code></pre>\n<ul>\n<li>If the piece contains the first bytes of a file</li>\n</ul>\n<pre><code class=\"language-txt\">..xx xxAA AA..\n</code></pre>\n<p>Then we save the data for that file in <code>file.start</code>.</p>\n<p>Note that we could seperate\nthis into 2 cases, but as we'll see later, not distinguishing these cases changes nothing in the end,\nand makes the algorithm simpler.</p>\n<ul>\n<li>If the piece contains the last bytes of a file:</li>\n</ul>\n<pre><code class=\"language-txt\">..AA AAxx xx..\n</code></pre>\n<p>Then we save the data for that file in <code>file.end</code>.</p>\n<h2>Data Structures and Algorithms</h2>\n<p>For each of these algorithms, our life is made much easier if we calculate a nicer representation\nof the file structure before hand. That is to say, we'll have a special representation of our\nfile structures used for writing the pieces, another for recomposing them, as well as a another,\nused for reading back the pieces.</p>\n<h3>Recomposing: Data Structure</h3>\n<p>The data structure for recomposing pieces together is pretty simple, for each final file in\nthe torrent, we keep a list of all its dependencies. That is to say, all the pieces that fit completly\ninto it, as well as all <code>file.end</code> and <code>file.start</code> if those exist.</p>\n<pre><code class=\"language-haskell\">data Recompose = Recompose [(File, [File])]\n</code></pre>\n<p>To make our algorithm easier, we want to make sure that the dependencies are in the same order as\nthey are in the file, so we can reconstruct the file by writing all dependencies in order.</p>\n<h3>Recomposing: Algorithm</h3>\n<p>The algorithm for recomposition is so simple, that we might as well already get it out of the way.\nThis also illustrates the benefit of this approach of using the most suitable data structure for\nimplementing our algorithms.</p>\n<pre><code class=\"language-haskell\">recompose (Recompose mappings) =\n    forM_ mappings $ \\(file, deps) -> do\n        when (allFilesExist deps) $ do\n            writeAllTo deps file\n            removeAll deps\n</code></pre>\n<p>For each file, we check if all its dependencies have already been written to,\nin which case we can reconstruct the file by concatenating all the dependencies.</p>\n<h3>Saving: Data Structure</h3>\n<p>In order to save each piece, we need to know which files the piece maps to,\nand how many bytes are in each piece. Our data structure thus looks like this:</p>\n<pre><code class=\"language-haskell\">data SavePieces = SavePieces (Piece -> [(Int, File)])\n</code></pre>\n<p>This contains a list of <code>(count, file)</code> tuples, listing the\nfiles the piece needs to be saved into, in the order they appear, as well\nas how many bytes of the piece should be saved in that file.</p>\n<h3>Saving: Algorithm</h3>\n<p>This algorithm is better expressed using an imperative formulation,\nbut a functional fold would be able to accomplish the same thing:</p>\n<pre><code class=\"language-py\">def save(piece, mappings):\n    bits = mappings(piece)\n    offset = 0\n    for (count, file) in bits:\n        write(file, piece[offset:offset+count])\n        offset += count\n</code></pre>\n<p>We just go linearly through each of the files, and save the right amount of the piece.\nFor this to work correctly, we need to make sure that the order of the files and counts\nis correct, otherwise we'll be saving the wrong part of the piece.</p>\n<h3>Reading: Data Structure</h3>\n<p>The main complexity with reading pieces from disk, is that the piece may be in different locations,\nat different times. At the start, a piece might be in different standalone files, some of which get merged\ninto a larger file. For example, a piece might map to <code>B.end</code> and <code>A.start</code>, in which case we need to know\nto read from <code>B.end</code> if it exists, otherwise from the right spot in <code>B</code>, and the same with <code>A</code>. Note that\nit might be the case that B is saved, but A is not, and vice versa.</p>\n<p>Let's start with a mapping from each piece to the locations it's stored in:</p>\n<pre><code class=\"language-haskell\">data ReadPieces = ReadPieces (Piece -> [Location])\n</code></pre>\n<p>Now, a location where a piece can be must contain both the small file containing just information for that piece,\nand then the large file where the piece will eventually be embedded.</p>\n<p>Thus, we have:</p>\n<pre><code class=\"language-haskell\">data Location = Location Embedded Complete\n\ntype Offset = Int\ntype Count = Int\ndata Embedded = Embedded File Offset Count\n\ndata Complete = Complete File\n</code></pre>\n<p>The embedded location contains the file, as well as the offset and count,\nallowing us to easily read the piece from the larger file. For the complete location,\nwe can just read that section by reading the entire small file.</p>\n<p>We need to store both locations, because we need to have both the complete, smaller location\nwhere that part of the piece is first stored, as well as the larger section of a big file where\nthe piece will eventually be located. We could keep all the small, temporary files around\nuntil the entire torrent is completed, but even once we've completed the whole torrent, we still\nneed to be able to read pieces in order to upload parts of the file to other pieces.</p>\n<h3>Reading: Algorithm</h3>\n<p>The algorithm can be given now that we've seen a good way to organise the data for this\ntask:</p>\n<pre><code class=\"language-haskell\">read (ReadPieces mapping) piece =\n    concatBS . forM (mapping piece) $ \\l -> do\n        let Location e c = l\n            Embedded fileE offset count = e\n            Complete fileC = c\n        complete &#x3C;- fileExists fileC\n        if complete\n            then readAll fileC\n            else readAt offset count fileE\n</code></pre>\n<p>We can safely assume that if the smaller, but complete, location no longer exists,\nthen this can only be because the larger file now does. We just concatenate the bytes\nfor each section of the piece, which we first try and read from the complete file, if it exists,\notherwise we go and read it from the embedded location of the larger file.</p>\n<h3>Interlude</h3>\n<p>We've made our life much easier by seperating everything into different distinct tasks,\nand using the right data structure for each of those tasks. Using the right data structure\nmakes the algorithm quite simple. One thing we have yet to see, however, is how to construct\nthese data structures from the information about the torrent file itself. That will have to wait\nfor the next post in this series; stay tuned for the next post then :)</p>","frontmatter":{"date":"May 03, 2019","image":"/print2.jpg","path":"/posts/bittorrent-the-hard-parts","title":"Bittorrent Is Hard - 1","description":"An algorithm for piece serialization"}}},"pageContext":{}}}