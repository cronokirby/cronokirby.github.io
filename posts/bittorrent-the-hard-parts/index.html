<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.201c9e6926874a8c50bd.css">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}a{background-color:transparent}img{border-style:none}[type=button],[type=reset],[type=submit]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring{outline:1px dotted ButtonText}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}[hidden]{display:none}html{box-sizing:border-box;font-family:sans-serif}*,:after,:before{box-sizing:inherit}h1,h2,ul{margin:0}ul{list-style:none;padding:0}html{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}*,:after,:before{border:0 solid #e2e8f0}img{border-style:solid}[role=button]{cursor:pointer}h1,h2{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}img,svg{display:block;vertical-align:middle}img{max-width:100%;height:auto}body,html{height:100%;background-color:#ebf8ff}.h-128{height:24rem}.blog-post-content{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-size:1.1em}.blog-post-content p{margin-top:1rem;margin-bottom:1rem}.blog-post-content h1{font-size:2.25rem;font-weight:700}.blog-post-content h2{font-size:1.875rem;font-weight:700}.blog-post-content h3{font-size:1.5rem;font-weight:700}.blog-post-content h4{font-size:1.25rem;font-weight:700}.blog-post-content pre{font-family:Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06);border-radius:.25rem;background-color:#fff;padding:.5rem .75rem;color:#4a5568}.blog-post-content a,.project a{text-decoration:underline}.blog-post-content ul{margin-left:2rem;margin-right:2rem;list-style-type:circle}.blog-post-content ol{margin-left:2rem;margin-right:2rem;list-style-type:decimal}.bg-white{background-color:#fff}.border-gray-700{border-color:#4a5568}.rounded{border-radius:.25rem}.flex{display:flex}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.items-baseline{align-items:baseline}.justify-start{justify-content:flex-start}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.flex-grow{flex-grow:1}.font-sans{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}.font-bold{font-weight:700}.h-48{height:12rem}.my-2{margin-top:.5rem;margin-bottom:.5rem}.mx-2{margin-left:.5rem;margin-right:.5rem}.mx-3{margin-left:.75rem;margin-right:.75rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mx-4{margin-left:1rem;margin-right:1rem}.mx-auto{margin-left:auto;margin-right:auto}.mt-2{margin-top:.5rem}.mr-3{margin-right:.75rem}.mr-4{margin-right:1rem}.mb-4{margin-bottom:1rem}.ml-4{margin-left:1rem}.object-cover{object-fit:cover}.object-top{object-position:top}.px-1{padding-left:.25rem;padding-right:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-2{padding-left:.5rem;padding-right:.5rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.shadow-md{box-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -1px rgba(0,0,0,.06)}.fill-current{fill:currentColor}.text-gray-700{color:#4a5568}.text-gray-800{color:#2d3748}.hover\:text-blue-600:hover{color:#3182ce}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-lg{font-size:1.125rem}.text-xl{font-size:1.25rem}.text-2xl{font-size:1.5rem}.text-3xl{font-size:1.875rem}.text-5xl{font-size:3rem}.italic{font-style:italic}.hover\:underline:hover{text-decoration:underline}.w-64{width:16rem}.w-11\/12{width:91.666667%}.w-full{width:100%}@media (min-width:640px){.sm\:justify-start{justify-content:flex-start}.sm\:mx-8{margin-right:2rem}.sm\:ml-8,.sm\:mx-8{margin-left:2rem}.sm\:px-8{padding-left:2rem;padding-right:2rem}.sm\:text-3xl{font-size:1.875rem}.sm\:w-64{width:16rem}.sm\:w-3\/4{width:75%}.sm\:w-5\/6{width:83.333333%}}@media (min-width:768px){.md\:mr-8{margin-right:2rem}}@media (min-width:1024px){.lg\:w-1\/2{width:50%}.lg\:w-2\/5{width:40%}}</style><meta name="generator" content="Gatsby 2.19.7"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true">Bittorrent Is Hard - 1 | Cronokirby</title><meta data-react-helmet="true" name="description" content="An algorithm for piece serialization"/><link as="script" rel="preload" href="/webpack-runtime-17acb63df39c58154676.js"/><link as="script" rel="preload" href="/styles-c965e640176e0ab1740b.js"/><link as="script" rel="preload" href="/app-8073d5687c4c20905145.js"/><link as="script" rel="preload" href="/commons-967143d3b6044aec96fc.js"/><link as="script" rel="preload" href="/component---src-templates-post-js-14f7f2443d2d260e6c40.js"/><link as="fetch" rel="preload" href="/page-data/posts/bittorrent-the-hard-parts/page-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" role="group" id="gatsby-focus-wrapper"><nav><ul class="flex items-baseline py-2 mx-auto mb-4 text-2xl px-4 sm:text-3xl font-bold text-gray-800 sm:w-3/4 lg:w-1/2"><li><a class="mr-4 hover:underline hover:text-blue-600 md:mr-8" href="/">Posts</a></li><li><a class="hover:underline hover:text-blue-600 sm:mx-8" href="/projects">Projects</a></li><li class="flex-grow"></li><li class="hover:text-blue-600"><a href="https://github.com/cronokirby"><svg width="32px" height="31px" viewBox="0 0 256 250" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid" class="fill-current"><g><path d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z"></path></g></svg></a></li><li class="ml-4 sm:ml-8 hover:text-blue-600"><a href="/rss.xml"><svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 430.117 430.118" class="fill-current"><g><path id="RSS" d="M97.493,332.473c10.419,10.408,16.755,24.525,16.794,40.244c-0.04,15.687-6.375,29.809-16.755,40.17l-0.04,0.019 c-10.398,10.352-24.603,16.681-40.398,16.681c-15.775,0-29.944-6.348-40.34-16.699C6.384,402.526,0,388.422,0,372.717 c0-15.719,6.384-29.869,16.754-40.253v0.009c10.401-10.36,24.57-16.735,40.34-16.735C72.89,315.738,87.081,322.131,97.493,332.473z M97.493,332.464v0.009c0.019,0,0.019,0,0.019,0L97.493,332.464z M16.754,412.906c0,0,0,0,0-0.019c-0.019,0-0.019,0-0.019,0 L16.754,412.906z M0.046,146.259v82.129c53.618,0.033,104.328,21.096,142.278,59.104c37.943,37.888,58.917,88.675,59.003,142.477 h0.028v0.149h82.467c-0.065-78.233-31.866-149.099-83.279-200.549C149.122,178.126,78.285,146.308,0.046,146.259z M0.196,0v82.089 c191.661,0.14,347.464,156.184,347.594,348.028h82.327c-0.056-118.571-48.248-225.994-126.132-303.932 C226.073,48.274,118.721,0.051,0.196,0z"></path></g></svg></a></li><li class="ml-4 sm:ml-8 hover:text-blue-600"><a href="https://twitter.com/cronokirby"><svg width="32px" height="26px" viewBox="0 0 256 209" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid" class="fill-current"><g><path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path></g></svg></a></li></ul></nav><div class="my-4 sm:w-5/6 lg:w-2/5 px-2 py-2 mx-auto text-gray-800 bg-white shadow-md rounded"><img src="/print2.jpg" alt="" class="h-128 w-full object-cover"/><div class="px-4 sm:px-8 py-4"><h2 class="text-xl text-brown-800 mt-2">May 03, 2019</h2><h1 class="text-5xl font-bold mb-4">Bittorrent Is Hard - 1</h1><div class="blog-post-content"><h2>About these posts</h2>
<p>I've been working on a <a href="https://github.com/cronokirby/haze">bittorrent client</a> in haskell
recently. It's now at the point where it can download torrents in the wild.</p>
<p>The <a href="https://wiki.theory.org/index.php/BitTorrentSpecification">protocol itself</a>
is well specified, although it takes a few read-throughs to get the hang of it.
The first time I read through the protocol I didn't understand much. But as I started
implementing different parts of the protocol, those parts of the document started making
more and more sense.</p>
<p>That being said, there are still many parts of the protocol where the specification might
be clear, but <em>how</em> to implement that specification is left as an exercise to the reader.
One of the sections that's most guilty of this is the section related to how peer's operate.
There are many subtle rules about what peers should do in certain situations; the details
of what variables to keep track of and how to make sure all these conditions are satisfied
is a big leap from this description though.</p>
<p>In these series of posts, I want to try and explain the details that go into some of the algorithms
necessary to implement <strong>Bittorrent</strong>.</p>
<p>This post covers how to save the pieces that make up the data in a torrent to disk, and how to recompose
those pieces back together.</p>
<h3>Side Note: What is Bittorrent?</h3>
<p>If you're already familiar with <strong>torrents</strong> or <strong>Bittorrent</strong>, then this section can be safely ignored.</p>
<p>Let me briefly explain these concepts.</p>
<p>Fundamentally, <strong>Bittorrent</strong> is a protocol that defines a way for multiple computers, which
we refer to as "peers", to download a file from eachother. Instead of each peer downloading
the file from a central server, they instead download different parts from eachother, and upload
the parts they have to the other peers that want those parts.</p>
<p>A <strong>torrent</strong> refers to this group of peers sharing a file.</p>
<h2>Torrents and Pieces</h2>
<p>A torrent can contain either a single file, or multiple files. When a torrent contains multiple files,
it can optionally contain a root directory for those files. For example, <code class="language-text">blockbuster.torrent</code> might
contain a single <code class="language-text">blockbuster.mp4</code> file, or perhaps <code class="language-text">blockbuster.mp4, blockbuster.subtitles</code> in a <code class="language-text">blockbuster</code> folder.</p>
<p>I mentioned previously that peers trade "parts" of a file. Instead of considering each peer as either having
the entire file, or not having it, and then downloading from those that have the <strong>whole</strong> file, we divide the file
into parts. We call these parts <strong>pieces</strong>. At any given point in time, we know which peers have which pieces (or at least, claim to), and what
pieces we have, and can make decisions about which piece to download next from whom.</p>
<p>The piece is also the unit of integrity of the torrent. Each piece has a SHA1 hash associated with it,
and when we receive a piece, we can hash the data inside, and see if it matches. This allows us to make sure that we're not
downloading junk data.</p>
<h2>Pieces and Division</h2>
<p>A torrent contains information about what files are in it, as mentioned previously. It also contains information about
how big the pieces are: this is a single number specifying how big each piece is.</p>
<p><strong>Complication: All pieces are the same size, except for the last one.</strong>
Let me illustrate this problem with an example. Let's say our piece size is 2 bytes, and our torrent contains 5 bytes
in total (let's skim over how this data is divided into files for now). Our data is divided like this:</p>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">xx xx x</code></pre></div>
<p>The first 2 pieces have the announced size, 2 bytes, but the last piece has to be whatever size necessary to "plug in"
the end of the data.</p>
<p>This is just an edge case to worry about, and not as tricky as the next complication:</p>
<p><strong>Complication: Pieces don't belong to one file</strong>
Let's continue using the same example as the previous complication, but further specify that the torrent actually
contains 2 files: A.png B.png. A is 3 bytes, and B 2 bytes. Our data would now look like this:</p>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">AA AB B</code></pre></div>
<p>The second piece now contains data from 2 different files!</p>
<p>This is because, as far as pieces are concerned, the torrent is just a binary blob. When peers are trading
pieces it's as if the torrent just contained a single file. In fact, in the case of a single file, we don't have this
problem at all, since all the pieces belong to this file.</p>
<p>When there are multiple files, they have a defined order. Conceptually, the binary data in these files
is concatenated together, in this predefined order, and then piece division happens as if it were a single file.
This means that a piece may actually contain data belonging to an arbitrary of files. It's actually quite
common for a piece to overlap many files. Because movies, which are large, often come with subtitles, which are relatively
much smaller, the piece size we use for those torrents are usually larger than the size of all the subtitles combined.
It's not uncommon for a single piece to actually contain all of the subtitles as well as a chunk of the movie itself:</p>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">ABCDEFGHIJXXXXXXXX XXXXX...</code></pre></div>
<h2>What our algorithm needs to do</h2>
<p>Now we get to the crux of this post: the algorithm for saving and retrieving pieces.</p>
<p>We can break down what we do with pieces into 3 seperate tasks:</p>
<ul>
<li>Recomposing the pieces into the torrent's files</li>
<li>Saving pieces to disk</li>
<li>Reading pieces from disk</li>
</ul>
<h3>Recomposing the pieces into the torrent's files</h3>
<p>After we've downloaded all the pieces, we need to actually assemble the files
that compose the torrent from the binary data in those pieces. We need to handle this somehow.
One option would be to wait until we have all pieces and then glue them together, another would be
to save to files as soon as we have all the pieces in that file.</p>
<h3>Saving the pieces to disk</h3>
<p>Although we could keep all pieces in memory until we have them all, and then flush them out to disk,
this doesn't work very well for actual torrents, which can easily be multiple gigabytes in size.
We need a way to save pieces to disk as they arrive, in such a way that we can easily recompose the pieces
into the files that make up the torrent once we have them all.</p>
<h3>Reading pieces from disk</h3>
<p>A key aspect of bittorrent is that peers aren't just downloading from other peers, but also
uploading the pieces of the files that they already have. Since we don't keep pieces in memory,
but instead save them to disk, we need a way to retrieve these pieces from disk. We also need
to be able to do this no matter what stage we're at. We need a way to read pieces back, whether
we've glued the pieces back into the torrent files yet or not.</p>
<p>I've stuck to details of the protocol itself so far. Now I'm going to describe the approach I came
up with for this algorithm. This is not at all a unique approach, nor is it the only, or best way
to tackle this problem.</p>
<h2>Piece files, start files, and end files</h2>
<p>Before we can even start on an algorithm to save pieces to to the right place, we need to decide
on what the "right place" is in the first place.</p>
<p>One choice would be to always work within
the files in the torrent: when we save a piece, we save different bits of the piece to different sections
of different files. We modify the final files directly. This has the advantage of not needing a final
recomposition step, since we're always working with the files themselves. The disadvantage is that the operation
of figuring out which sections of which files to write to is quite complicated.</p>
<p>Another approach, which is the one I chose, is instead to use as many files as convenient, and then
recompose them together as a final step. For example, instead of trying to figure out where "piece #38"
needs to go, we just save it in <code class="language-text">piece-38.bin</code> and worry about recomposing it later.</p>
<p>We identify the following cases for how we save pieces:</p>
<ul>
<li>The piece belongs completely into a single file:</li>
</ul>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">..xx xxxx xx..</code></pre></div>
<p>In this case we save <code class="language-text">piece #N</code> to <code class="language-text">piece-N.bin</code>.</p>
<ul>
<li>The piece belongs to multiple files:</li>
</ul>
<p>In this case, we will save the piece into N files, where N is the number of
files the piece belongs to. What these files are named depends on the following:</p>
<ul>
<li>If a file fits completely into a piece:</li>
</ul>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">xxAAAyy</code></pre></div>
<ul>
<li>If the piece contains the first bytes of a file</li>
</ul>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">..xx xxAA AA..</code></pre></div>
<p>Then we save the data for that file in <code class="language-text">file.start</code>.</p>
<p>Note that we could seperate
this into 2 cases, but as we'll see later, not distinguishing these cases changes nothing in the end,
and makes the algorithm simpler.</p>
<ul>
<li>If the piece contains the last bytes of a file:</li>
</ul>
<div class="gatsby-highlight" data-language="txt"><pre class="language-txt"><code class="language-txt">..AA AAxx xx..</code></pre></div>
<p>Then we save the data for that file in <code class="language-text">file.end</code>.</p>
<h2>Data Structures and Algorithms</h2>
<p>For each of these algorithms, our life is made much easier if we calculate a nicer representation
of the file structure before hand. That is to say, we'll have a special representation of our
file structures used for writing the pieces, another for recomposing them, as well as a another,
used for reading back the pieces.</p>
<h3>Recomposing: Data Structure</h3>
<p>The data structure for recomposing pieces together is pretty simple, for each final file in
the torrent, we keep a list of all its dependencies. That is to say, all the pieces that fit completly
into it, as well as all <code class="language-text">file.end</code> and <code class="language-text">file.start</code> if those exist.</p>
<div class="gatsby-highlight" data-language="haskell"><pre class="language-haskell"><code class="language-haskell"><span class="token keyword">data</span> <span class="token constant">Recompose</span> <span class="token operator">=</span> <span class="token constant">Recompose</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token constant">File</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token constant">File</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre></div>
<p>To make our algorithm easier, we want to make sure that the dependencies are in the same order as
they are in the file, so we can reconstruct the file by writing all dependencies in order.</p>
<h3>Recomposing: Algorithm</h3>
<p>The algorithm for recomposition is so simple, that we might as well already get it out of the way.
This also illustrates the benefit of this approach of using the most suitable data structure for
implementing our algorithms.</p>
<div class="gatsby-highlight" data-language="haskell"><pre class="language-haskell"><code class="language-haskell"><span class="token hvariable">recompose</span> <span class="token punctuation">(</span><span class="token constant">Recompose</span> <span class="token hvariable">mappings</span><span class="token punctuation">)</span> <span class="token operator">=</span>
    <span class="token hvariable">forM_</span> <span class="token hvariable">mappings</span> <span class="token operator">$</span> <span class="token operator">\</span><span class="token punctuation">(</span><span class="token hvariable">file</span><span class="token punctuation">,</span> <span class="token hvariable">deps</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">do</span>
        <span class="token hvariable">when</span> <span class="token punctuation">(</span><span class="token hvariable">allFilesExist</span> <span class="token hvariable">deps</span><span class="token punctuation">)</span> <span class="token operator">$</span> <span class="token keyword">do</span>
            <span class="token hvariable">writeAllTo</span> <span class="token hvariable">deps</span> <span class="token hvariable">file</span>
            <span class="token hvariable">removeAll</span> <span class="token hvariable">deps</span></code></pre></div>
<p>For each file, we check if all its dependencies have already been written to,
in which case we can reconstruct the file by concatenating all the dependencies.</p>
<h3>Saving: Data Structure</h3>
<p>In order to save each piece, we need to know which files the piece maps to,
and how many bytes are in each piece. Our data structure thus looks like this:</p>
<div class="gatsby-highlight" data-language="haskell"><pre class="language-haskell"><code class="language-haskell"><span class="token keyword">data</span> <span class="token constant">SavePieces</span> <span class="token operator">=</span> <span class="token constant">SavePieces</span> <span class="token punctuation">(</span><span class="token constant">Piece</span> <span class="token operator">-></span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token constant">Int</span><span class="token punctuation">,</span> <span class="token constant">File</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>This contains a list of <code class="language-text">(count, file)</code> tuples, listing the
files the piece needs to be saved into, in the order they appear, as well
as how many bytes of the piece should be saved in that file.</p>
<h3>Saving: Algorithm</h3>
<p>This algorithm is better expressed using an imperative formulation,
but a functional fold would be able to accomplish the same thing:</p>
<div class="gatsby-highlight" data-language="py"><pre class="language-py"><code class="language-py"><span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>piece<span class="token punctuation">,</span> mappings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    bits <span class="token operator">=</span> mappings<span class="token punctuation">(</span>piece<span class="token punctuation">)</span>
    offset <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>count<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span> <span class="token keyword">in</span> bits<span class="token punctuation">:</span>
        write<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> piece<span class="token punctuation">[</span>offset<span class="token punctuation">:</span>offset<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>
        offset <span class="token operator">+=</span> count</code></pre></div>
<p>We just go linearly through each of the files, and save the right amount of the piece.
For this to work correctly, we need to make sure that the order of the files and counts
is correct, otherwise we'll be saving the wrong part of the piece.</p>
<h3>Reading: Data Structure</h3>
<p>The main complexity with reading pieces from disk, is that the piece may be in different locations,
at different times. At the start, a piece might be in different standalone files, some of which get merged
into a larger file. For example, a piece might map to <code class="language-text">B.end</code> and <code class="language-text">A.start</code>, in which case we need to know
to read from <code class="language-text">B.end</code> if it exists, otherwise from the right spot in <code class="language-text">B</code>, and the same with <code class="language-text">A</code>. Note that
it might be the case that B is saved, but A is not, and vice versa.</p>
<p>Let's start with a mapping from each piece to the locations it's stored in:</p>
<div class="gatsby-highlight" data-language="haskell"><pre class="language-haskell"><code class="language-haskell"><span class="token keyword">data</span> <span class="token constant">ReadPieces</span> <span class="token operator">=</span> <span class="token constant">ReadPieces</span> <span class="token punctuation">(</span><span class="token constant">Piece</span> <span class="token operator">-></span> <span class="token punctuation">[</span><span class="token constant">Location</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>Now, a location where a piece can be must contain both the small file containing just information for that piece,
and then the large file where the piece will eventually be embedded.</p>
<p>Thus, we have:</p>
<div class="gatsby-highlight" data-language="haskell"><pre class="language-haskell"><code class="language-haskell"><span class="token keyword">data</span> <span class="token constant">Location</span> <span class="token operator">=</span> <span class="token constant">Location</span> <span class="token constant">Embedded</span> <span class="token constant">Complete</span>

<span class="token keyword">type</span> <span class="token constant">Offset</span> <span class="token operator">=</span> <span class="token constant">Int</span>
<span class="token keyword">type</span> <span class="token constant">Count</span> <span class="token operator">=</span> <span class="token constant">Int</span>
<span class="token keyword">data</span> <span class="token constant">Embedded</span> <span class="token operator">=</span> <span class="token constant">Embedded</span> <span class="token constant">File</span> <span class="token constant">Offset</span> <span class="token constant">Count</span>

<span class="token keyword">data</span> <span class="token constant">Complete</span> <span class="token operator">=</span> <span class="token constant">Complete</span> <span class="token constant">File</span></code></pre></div>
<p>The embedded location contains the file, as well as the offset and count,
allowing us to easily read the piece from the larger file. For the complete location,
we can just read that section by reading the entire small file.</p>
<p>We need to store both locations, because we need to have both the complete, smaller location
where that part of the piece is first stored, as well as the larger section of a big file where
the piece will eventually be located. We could keep all the small, temporary files around
until the entire torrent is completed, but even once we've completed the whole torrent, we still
need to be able to read pieces in order to upload parts of the file to other pieces.</p>
<h3>Reading: Algorithm</h3>
<p>The algorithm can be given now that we've seen a good way to organise the data for this
task:</p>
<div class="gatsby-highlight" data-language="haskell"><pre class="language-haskell"><code class="language-haskell"><span class="token builtin">read</span> <span class="token punctuation">(</span><span class="token constant">ReadPieces</span> <span class="token hvariable">mapping</span><span class="token punctuation">)</span> <span class="token hvariable">piece</span> <span class="token operator">=</span>
    <span class="token hvariable">concatBS</span><span class="token operator"> . </span><span class="token hvariable">forM</span> <span class="token punctuation">(</span><span class="token hvariable">mapping</span> <span class="token hvariable">piece</span><span class="token punctuation">)</span> <span class="token operator">$</span> <span class="token operator">\</span><span class="token hvariable">l</span> <span class="token operator">-></span> <span class="token keyword">do</span>
        <span class="token keyword">let</span> <span class="token constant">Location</span> <span class="token hvariable">e</span> <span class="token hvariable">c</span> <span class="token operator">=</span> <span class="token hvariable">l</span>
            <span class="token constant">Embedded</span> <span class="token hvariable">fileE</span> <span class="token hvariable">offset</span> <span class="token hvariable">count</span> <span class="token operator">=</span> <span class="token hvariable">e</span>
            <span class="token constant">Complete</span> <span class="token hvariable">fileC</span> <span class="token operator">=</span> <span class="token hvariable">c</span>
        <span class="token hvariable">complete</span> <span class="token operator">&lt;-</span> <span class="token hvariable">fileExists</span> <span class="token hvariable">fileC</span>
        <span class="token keyword">if</span> <span class="token hvariable">complete</span>
            <span class="token keyword">then</span> <span class="token hvariable">readAll</span> <span class="token hvariable">fileC</span>
            <span class="token keyword">else</span> <span class="token hvariable">readAt</span> <span class="token hvariable">offset</span> <span class="token hvariable">count</span> <span class="token hvariable">fileE</span></code></pre></div>
<p>We can safely assume that if the smaller, but complete, location no longer exists,
then this can only be because the larger file now does. We just concatenate the bytes
for each section of the piece, which we first try and read from the complete file, if it exists,
otherwise we go and read it from the embedded location of the larger file.</p>
<h3>Interlude</h3>
<p>We've made our life much easier by seperating everything into different distinct tasks,
and using the right data structure for each of those tasks. Using the right data structure
makes the algorithm quite simple. One thing we have yet to see, however, is how to construct
these data structures from the information about the torrent file itself. That will have to wait
for the next post in this series; stay tuned for the next post then :)</p></div></div></div></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/posts/bittorrent-the-hard-parts";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-8073d5687c4c20905145.js"],"component---src-templates-post-js":["/component---src-templates-post-js-14f7f2443d2d260e6c40.js"],"component---src-templates-taglist-js":["/component---src-templates-taglist-js-4e73baba17f2809213f8.js"],"component---src-pages-index-js":["/component---src-pages-index-js-692e6b36443326de1282.js"],"component---src-pages-projects-js":["/component---src-pages-projects-js-a7ac0af32a6c0876c89c.js"]};/*]]>*/</script><script src="/component---src-templates-post-js-14f7f2443d2d260e6c40.js" async=""></script><script src="/commons-967143d3b6044aec96fc.js" async=""></script><script src="/app-8073d5687c4c20905145.js" async=""></script><script src="/styles-c965e640176e0ab1740b.js" async=""></script><script src="/webpack-runtime-17acb63df39c58154676.js" async=""></script></body></html>